{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Kodo-python Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the getting started ipython notebook for kodo-python.\n",
    "\n",
    "This guide is intended for newcomers to the Kodo library. The guide will in tiny steps guide you through the creation and usage of both encoders and decoders.\n",
    "Even though this guide focuses on the the python language bindings of Kodo - similar APIs exists for other languages including C, C++ and Java."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Importing Kodo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before working with Kodo-python, you obviously need to have it installed and available. To ensure that's the case, try importing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kodo imported Succesfully\n"
     ]
    }
   ],
   "source": [
    "# try importing the ``kodo`` module\n",
    "try:\n",
    "    import kodo\n",
    "    print(\"Kodo imported Succesfully\")\n",
    "except ImportError:\n",
    "    print(\"Unable to import kodo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the import worked, you are ready to move on to the next step. Otherwise please (re)visit the README.rst for installation instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In kodo, both encoders and decoders are created using factories. Doing so allows efficient memory management and reuse of various components and computations. \n",
    "\n",
    "Therefore, before creating an encoder, let's look at the encoder factories provided by the ``kodo`` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullVectorEncoderFactoryBinary\n",
      "FullVectorEncoderFactoryBinary16\n",
      "FullVectorEncoderFactoryBinary4\n",
      "FullVectorEncoderFactoryBinary8\n",
      "NoCodeEncoderFactory\n",
      "OnTheFlyEncoderFactoryBinary\n",
      "OnTheFlyEncoderFactoryBinary16\n",
      "OnTheFlyEncoderFactoryBinary4\n",
      "OnTheFlyEncoderFactoryBinary8\n",
      "PerpetualEncoderFactoryBinary\n",
      "PerpetualEncoderFactoryBinary16\n",
      "PerpetualEncoderFactoryBinary4\n",
      "PerpetualEncoderFactoryBinary8\n",
      "SlidingWindowEncoderFactoryBinary\n",
      "SlidingWindowEncoderFactoryBinary16\n",
      "SlidingWindowEncoderFactoryBinary4\n",
      "SlidingWindowEncoderFactoryBinary8\n",
      "SparseFullVectorEncoderFactoryBinary\n",
      "SparseFullVectorEncoderFactoryBinary16\n",
      "SparseFullVectorEncoderFactoryBinary4\n",
      "SparseFullVectorEncoderFactoryBinary8\n"
     ]
    }
   ],
   "source": [
    "# print all members containing \"Factory\" and \"Encoder\"\n",
    "print(\"\\n\".join([item for item in dir(kodo) if all([keyword in item for keyword in [\"Factory\", \"Encoder\"]])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the output, many different encoder factories exists. Most of these have decoder factory counterparts.\n",
    "\n",
    "The factory names are, with some exceptions, a combination of the encoding algorithm and the underlying finite field.\n",
    "\n",
    "For this walk through we pick the full vector factory using the binary field, i.e. the **``FullVector``**``EncoderFactory``**``Binary``** factory.\n",
    "\n",
    "Note: *For this guide, any of the factories should work. For this reason I'll define the factory class as ``EncoderFactory``.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store the full vector binary encoder factory as EncoderFactory\n",
    "EncoderFactory = kodo.FullVectorEncoderFactoryBinary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using python's ``help`` function, we can inspect the  ``EncoderFactory``'s constructor: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method __init__:\n",
      "\n",
      "__init__(...) unbound kodo.FullVectorEncoderFactoryBinary method\n",
      "    Factory constructor.\n",
      "    \n",
      "            :param max_symbols: The maximum symbols the coders can expect.\n",
      "            :param max_symbol_size: The maximum size of a symbol in bytes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get information about the encoder factory's __init__ function\n",
    "help(EncoderFactory.__init__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the documentation, we can see that we need to provide the ``max_symbols`` and ``max_symbol_size`` to create a factory.\n",
    "\n",
    "These parameters determines upper bounds to the encoders created by the factory.\n",
    "\n",
    "The proper values to pick depends on the use case, we'll pick the numbers 4 and 32 for the max_symbols and max_symbol_size, respectively.\n",
    "These numbers would be very low for a real work use case, but they serve us well for this example.\n",
    "\n",
    "Let's create an encoder_factory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_symbols = 4\n",
    "max_symbol_size = 32\n",
    "\n",
    "encoder_factory = EncoderFactory(\n",
    "    max_symbols=max_symbols,\n",
    "    max_symbol_size=max_symbol_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see which methods are available for the encoder_factory, we can use python's ``dir`` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\n",
      "max_block_size\n",
      "max_payload_size\n",
      "max_symbol_size\n",
      "max_symbols\n",
      "set_symbol_size\n",
      "set_symbols\n",
      "symbol_size\n",
      "symbols\n"
     ]
    }
   ],
   "source": [
    "# Print all public members\n",
    "print(\"\\n\".join([item for item in dir(encoder_factory) if not item.startswith(\"__\")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``build`` is the one used for creating encoders, but it's not the only interesting method available.\n",
    "\n",
    "Let's print out the maximum block size, i.e. the maximum amount of data that can be encoded during each generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max block size: 128\n"
     ]
    }
   ],
   "source": [
    "max_block_size = encoder_factory.max_block_size()\n",
    "print(\"Max block size: {}\".format(max_block_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the maximum block size is directly correlated with the previously set ``max_symbols`` and ``max_symbol_size``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated max block size: 128\n"
     ]
    }
   ],
   "source": [
    "calculated_max_block_size = max_symbols * max_symbol_size\n",
    "print(\"Calculated max block size: {}\".format(calculated_max_block_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enough talk - let's create an encoder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = encoder_factory.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic, we've build our first encoder! Let's see what we can use it for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_size\n",
      "in_systematic_phase\n",
      "is_systematic_on\n",
      "payload_size\n",
      "rank\n",
      "set_symbol\n",
      "set_symbols\n",
      "set_systematic_off\n",
      "set_systematic_on\n",
      "symbol_size\n",
      "symbols\n",
      "trace\n",
      "write_payload\n"
     ]
    }
   ],
   "source": [
    "# Print all public members\n",
    "print(\"\\n\".join([item for item in dir(encoder) if not item.startswith(\"__\")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the state of our newly created encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_size: 128\n",
      "is_systematic_on: True\n",
      "in_systematic_phase: False\n",
      "payload_size: 38\n",
      "rank: 0\n",
      "symbol_size: 32\n",
      "symbols: 4\n"
     ]
    }
   ],
   "source": [
    "def print_encoder_state(encoder):\n",
    "    print(\n",
    "        \"block_size: {}\\n\"\n",
    "        \"is_systematic_on: {}\\n\"\n",
    "        \"in_systematic_phase: {}\\n\"\n",
    "        \"payload_size: {}\\n\"\n",
    "        \"rank: {}\\n\"\n",
    "        \"symbol_size: {}\\n\"\n",
    "        \"symbols: {}\".format(\n",
    "            encoder.block_size(),\n",
    "            encoder.is_systematic_on(),\n",
    "            encoder.in_systematic_phase(),\n",
    "            encoder.payload_size(),\n",
    "            encoder.rank(),\n",
    "            encoder.symbol_size(),\n",
    "            encoder.symbols())\n",
    "    )\n",
    "print_encoder_state(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the ``write_payload`` method to encode the data, but since we have yet to tell encoder what data to encode, we can't use it yet.\n",
    "This can be seen from the encoder rank which is 0.\n",
    "\n",
    "Let's create some data to encode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data string: 128\n"
     ]
    }
   ],
   "source": [
    "data_in = (\n",
    "    \"The size of this data is exactly 128 bytes \"\n",
    "    \"which means it will fit perfectly in a single generation. \"\n",
    "    \"That is very lucky, indeed!\"\n",
    ")\n",
    "print(\"Length of data string: {}\".format(len(data_in)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kodo uses python strings as data objects, which means each character represents a byte. Let's set the data to encode on the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder.set_symbols(data_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now be able to see how the state of the encoder has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_size: 128\n",
      "is_systematic_on: True\n",
      "in_systematic_phase: True\n",
      "payload_size: 38\n",
      "rank: 4\n",
      "symbol_size: 32\n",
      "symbols: 4\n"
     ]
    }
   ],
   "source": [
    "print_encoder_state(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the rank is now equal to the number of symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.rank() == max_symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can only encode packets if the rank is ``> 0``.\n",
    "\n",
    "Let's encode some packets using the ``write_payload`` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packet1: �\u0000\u0000\u0000\u0000The size of this data is exactly\n",
      "packet2: �\u0000\u0000\u0000\u0001 128 bytes which means it will f\n",
      "packet3: �\u0000\u0000\u0000\u0002it perfectly in a single generat\n",
      "packet4: �\u0000\u0000\u0000\u0003ion. That is very lucky, indeed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "packet1 = encoder.write_payload()\n",
    "packet2 = encoder.write_payload()\n",
    "packet3 = encoder.write_payload()\n",
    "packet4 = encoder.write_payload()\n",
    "\n",
    "print(\n",
    "    \"packet1: {}\\n\"\n",
    "    \"packet2: {}\\n\"\n",
    "    \"packet3: {}\\n\"\n",
    "    \"packet4: {}\\n\".format(\n",
    "        packet1,\n",
    "        packet2,\n",
    "        packet3,\n",
    "        packet4,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how all the packets are prefixed with ``�`` - this is python trying to print the packet header containing the symbol id.\n",
    "\n",
    "The reason why the content of the packets are readable is that the encoder is in systematic phase. Systematic means that the encoder starts by leaving each symbol uncoded in the first iteration.\n",
    "\n",
    "Because we've set the generation size to be 4 symbols, and we've created 4 packets - the encoder is no longer in systematic phase:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.in_systematic_phase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that any subsequent packets we generate, will be encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packet5: \u0000�Ts+~6Ota7;c*twb!8d~hl,|: kskcci,\n"
     ]
    }
   ],
   "source": [
    "packet5 = encoder.write_payload()\n",
    "print(\"packet5: {}\".format(packet5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the encoding is random, the data could still be uncoded, it will however most likely be unreadable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a decoder factory and a decoder so that we can decode our newly generated packets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_factory = kodo.FullVectorDecoderFactoryBinary(max_symbols, max_symbol_size)\n",
    "decoder = decoder_factory.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate which methods that are available for the decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_size\n",
      "copy_symbols\n",
      "is_complete\n",
      "payload_size\n",
      "rank\n",
      "read_payload\n",
      "symbol_size\n",
      "symbols\n",
      "symbols_uncoded\n",
      "trace\n",
      "write_payload\n"
     ]
    }
   ],
   "source": [
    "# Print all public members\n",
    "print(\"\\n\".join([item for item in dir(decoder) if not item.startswith(\"__\")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the output, the encoder and decoder shares a few methods. Most of these have the same meaning.\n",
    "Let's inspect the state of our newly created decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_size: 128\n",
      "is_complete: False\n",
      "payload_size: 38\n",
      "rank: 0\n",
      "symbol_size: 32\n",
      "symbols: 4\n",
      "symbols_uncoded: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_decoder_state(decoder):\n",
    "    print(\n",
    "        \"block_size: {}\\n\"\n",
    "        \"is_complete: {}\\n\"\n",
    "        \"payload_size: {}\\n\"\n",
    "        \"rank: {}\\n\"\n",
    "        \"symbol_size: {}\\n\"\n",
    "        \"symbols: {}\\n\"\n",
    "        \"symbols_uncoded: {}\\n\".format(\n",
    "            decoder.block_size(),\n",
    "            decoder.is_complete(),\n",
    "            decoder.payload_size(),\n",
    "            decoder.rank(),\n",
    "            decoder.symbol_size(),\n",
    "            decoder.symbols(),\n",
    "            decoder.symbols_uncoded())\n",
    "    )\n",
    "print_decoder_state(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's probably the most interesting here is the rank. The rank is describes the number of innovative packets received."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we read one of our previously generated packets, we should see the rank increase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.read_payload(packet1)\n",
    "decoder.rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it does.\n",
    "\n",
    "We can now try to read the 5th packet, and see what it does to the state. The unique thing about the 5th packet, is that it's the only one which have been encoded, due to our encoder being systematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_size: 128\n",
      "is_complete: False\n",
      "payload_size: 38\n",
      "rank: 2\n",
      "symbol_size: 32\n",
      "symbols: 4\n",
      "symbols_uncoded: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder.read_payload(packet5)\n",
    "print_decoder_state(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rank has increased to 2! This means that we've read two (innovative) packets. If extract the current data in the decoder we get the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The size of this data is exactly_________________________________\\x1bN^E&\\x0e\\x04\\x17T\\x05\\n_\\x1f\\x0bR\\x18_\\x1f\\x1c\\r\\x0c\\x15I_\\x0e\\x0b\\n_\\x17\\x05U________________________________'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.copy_symbols().replace('\\x00', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the first part of the string is readable. Depending on the encoding of the 5th packet other parts of the string may or may not be readable.\n",
    "\n",
    "If we feed the same packet(s) to the decoder multiple times we will not increase it's rank - no matter how many times we do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank after rereading packet1: 2\n",
      "Rank after rereading packet5: 2\n",
      "Rank after rereading 100 times: 2\n"
     ]
    }
   ],
   "source": [
    "# Once\n",
    "decoder.read_payload(packet1)\n",
    "print(\"Rank after rereading packet1: {}\".format(decoder.rank()))\n",
    "decoder.read_payload(packet5)\n",
    "print(\"Rank after rereading packet5: {}\".format(decoder.rank()))\n",
    "\n",
    "# A 100 times\n",
    "for i in range(100):\n",
    "    decoder.read_payload(packet1)\n",
    "    decoder.read_payload(packet5)\n",
    "\n",
    "print(\"Rank after rereading 100 times: {}\".format(decoder.rank()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because the data we feed the decoder isn't innovative.\n",
    "\n",
    "Note, the rank can at most increaes by one when reading a packet.\n",
    "\n",
    "If we start feeding the decoder new data, we will at one point have a complete decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "while not decoder.is_complete():\n",
    "    decoder.read_payload(encoder.write_payload())\n",
    "    print(decoder.rank())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And when the decoder is complete we should be able to extract the whole string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of this data is exactly 128 bytes which means it will fit perfectly in a single generation. That is very lucky, indeed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out = decoder.copy_symbols()\n",
    "print(data_out)\n",
    "data_out == data_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hurray, it worked!\n",
    "\n",
    "For more information and inspiration please look through some of the many examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
